# -*- coding: utf-8 -*-
"""Feature Construction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aOOga_iQGdYhMwdhwP0I-bG2T8jiq45w

# Introduction

In this tutorial ,i am going to talk about categorical variables and using original features of the data set to construct new features and why we could do that .

# Categorical features

A categorical feature takes only a limited number of values.
Consider a survey that asks how often you eat breakfast and provides four options: "Never", "Rarely", "Most days", or "Every day". In this case, the data is categorical, because responses fall into a fixed set of categories.
If people responded to a survey about which what brand of car they owned, the responses would fall into categories like "Honda", "Toyota", and "Ford". In this case, the data is also categorical.
You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first.
There are many approaches that you can use to prepare your categorical data , and i will talk about 3 of them.

# Approaches to handle categorical features
"""

import pandas as pd
df=pd.read_csv('https://github.com/Omarsawan/data/blob/master/ks-projects-201801.csv')
df.head(6)